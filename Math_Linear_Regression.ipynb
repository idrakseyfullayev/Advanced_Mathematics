{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "585eed3b",
   "metadata": {},
   "source": [
    "## Linear regression modelində törəmə"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63cd5f4",
   "metadata": {},
   "source": [
    "Linear regression modelində törəmə (derivative) əsasən **xəta funksiyasının minimallaşdırılması** prosesində istifadə olunur. Modelin məqsədi, verilən məlumatlara ən yaxşı uyğun gələn xətti təyin etməkdir. Bu məqsədlə, xəta funksiyası (məsələn, MSE - Mean Squared Error) istifadə edilir və törəmə bu funksiyanın minimum nöqtəsini tapmaq üçün istifadə olunur.\n",
    "\n",
    "### Törəmə ilə regresyonun tətbiqi:\n",
    "1. **Xəta funksiyası**:\n",
    "   Linear regression-da xəta funksiyası adətən aşağıdakı kimi ifadə olunur:\n",
    "   $$\n",
    "   J(\\theta) = \\frac{1}{2m} \\sum_{i=1}^{m} \\left( \\hat{y_i} - y_i \\right)^2\n",
    "  $$\n",
    "   Burada:\n",
    "   - $ \\hat{y_i} $ modelin proqnozlaşdırdığı qiymətdir,\n",
    "   - $ y_i $ isə gerçək qiymətdir,\n",
    "   - $ m $ isə nümunələrin sayıdır.\n",
    "\n",
    "2. **Törəmə alınması**:\n",
    "   Xəta funksiyasını minimuma endirmək üçün onun törəməsini alırıq. Törəmə ilə biz hansı dərəcədə dəyişdirməli olduğumuzu tapırıq ki, xəta ən aşağı səviyyəyə insin.\n",
    "\n",
    "   **Törəmə alındıqda**:\n",
    "   $$\n",
    "   \\frac{\\partial J(\\theta)}{\\partial \\theta_0} = \\frac{1}{m} \\sum_{i=1}^{m} \\left( \\hat{y_i} - y_i \\right)\n",
    "   $$\n",
    "   $$\n",
    "   \\frac{\\partial J(\\theta)}{\\partial \\theta_j} = \\frac{1}{m} \\sum_{i=1}^{m} \\left( \\hat{y_i} - y_i \\right) x_{ij}, \\quad \\text{for} \\ j = 1, 2, \\dots, n\n",
    "   $$\n",
    "\n",
    "3. **Gradient Descent (Gradientsiz Aşağı eniş)**:\n",
    "   Törəmələrdən istifadə edərək, **gradient descent** (dərəcəli eniş) metodu ilə **\\(\\theta\\)** parametrlərini optimallaşdırırıq:\n",
    "   $$\n",
    "   \\theta_j := \\theta_j - \\alpha \\cdot \\frac{\\partial J(\\theta)}{\\partial \\theta_j}\n",
    "   $$\n",
    "   Burada $ \\alpha $ öyrənmə sürətidir. Bu prosedur hər iterasiyada parametrləri yeniləyir və xəta funksiyasını minimuma endirir.\n",
    "\n",
    "Nəticədə, törəmə, modelin parametrlərini təkmilləşdirmək və ən yaxşı uyğun xətti tapmaq üçün əsas vasitədir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7353feff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fcce074b",
   "metadata": {},
   "source": [
    "## $ \\frac{1}{2m} $ faktoru"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f36d634",
   "metadata": {},
   "source": [
    "---\n",
    "$ \\frac{1}{2m} $ faktorunun istifadə olunma səbəbi **xəta funksiyasının törəməsini sadələşdirmək** məqsədidir. Gəlin bu addımları ətraflı izah edək:\n",
    "\n",
    "### 1. **Xəta funksiyasının təyin edilməsi**:\n",
    "Linear regression-da məqsədimiz modelin **proqnozlaşdırdığı qiymətləri** və **real qiymətləri** arasındakı fərqi ölçməkdir. Bu fərqi ölçmək üçün adətən **orta kvadrat xətası** (Mean Squared Error, MSE) istifadə edilir:\n",
    "$$\n",
    "J(\\theta) = \\frac{1}{2m} \\sum_{i=1}^{m} \\left( \\hat{y_i} - y_i \\right)^2\n",
    "$$\n",
    "Burada:\n",
    "- $ \\hat{y_i} = \\theta_0 + \\theta_1 x_i $ modelin proqnozlaşdırdığı qiymətdir,\n",
    "- $ y_i $ isə real qiymətdir,\n",
    "- $ m $ isə nümunələrin sayıdır.\n",
    "\n",
    "### 2. **Törəmənin sadələşdirilməsi**:\n",
    "Xəta funksiyasını **törəməsini alarkən** $ \\frac{1}{2m} $ faktoru istifadə etməyin əsas səbəbi onun daha asan hesablanmasını təmin etməkdir.\n",
    "\n",
    "- **Törəmənin alındığı zaman**:\n",
    "  $$\n",
    "  \\frac{\\partial}{\\partial \\theta_j} \\left( \\sum_{i=1}^{m} \\left( \\hat{y_i} - y_i \\right)^2 \\right)\n",
    "  $$\n",
    "  Bu ifadənin törəməsini alanda, **2** saylı faktoru çıxarırıq, çünki \\( \\left( \\hat{y_i} - y_i \\right)^2 \\)-nin törəməsi $2 (\\hat{y_i} - y_i) $-ni verəcək. Əgər əvvəldən $ \\frac{1}{2} $ varsa, bu faktoru **aradan qaldırırıq**.\n",
    "\n",
    "  - Bu, **hesablama işini asanlaşdırır**, çünki törəmə əməliyyatı nəticəsində 2-lər bir-birini ləğv edir və daha sadə bir nəticə əldə edirik.\n",
    "\n",
    "### 3. **Törəmənin nəticəsi**:\n",
    "Əgər bu $ \\frac{1}{2m} $ faktoru olmasaydı, törəmə zamanı 2-lər qalar və **öyrənmə sürətinin tənzimlənməsi** və ya **gradient descent** nəticələrinin hesablanması bir az daha çətinləşərdi.\n",
    "\n",
    "Beləliklə, $ \\frac{1}{2m} $-nin istifadəsi sadəcə **hesablama rahatlığı** və **törəmənin asan olması** üçün edilir. Bu, nəticədə modelin optimallaşdırılmasını sadələşdirir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2dbc4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3d2578e4",
   "metadata": {},
   "source": [
    "##  Linear Regression modelində x² və x³ kimi dəyişənlərin törəməsi alınmır."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3c461f",
   "metadata": {},
   "source": [
    "---\n",
    "Bəli, doğru başa düşdünüz. **Modeldən** söhbət gedir və **linear regression** modelində **x²** və **x³** kimi dəyişənlərin törəməsi alınmır. \n",
    "\n",
    "**Modelin** məqsədi **xətti əlaqə qurmaqdır**, və modelin optimallaşdırılmasında **x²** və **x³** kimi xüsusiyyətlər yalnız **yeni dəyişənlər** kimi istifadə olunur, **onların törəməsi alınmaz**.\n",
    "\n",
    "### Gəlin, bu prosesi aydınlaşdıraq:\n",
    "\n",
    "1. **Polinomial xüsusiyyətlər**: \n",
    "   Əgər modeldə **x²** və **x³** istifadə olunursa, bu xüsusiyyətlər **yeni dəyişənlər kimi qəbul edilir** və **linear regression** bu xüsusiyyətlər üzərində **xətti əlaqə qurur**.\n",
    "   \n",
    "   Məsələn, əgər model aşağıdakı kimi yazılırsa:\n",
    "   $$\n",
    "   y = \\theta_0 + \\theta_1 x + \\theta_2 x^2 + \\theta_3 x^3\n",
    "   $$\n",
    "   Burada **x²** və **x³** dəyişənlər olaraq modelə daxil edilir, lakin model **hər hansı bir törəmə əməliyyatı etməz**. Bu dəyişənlər sadəcə yeni **xüsusiyyətlər** kimi modelə daxil olunur.\n",
    "\n",
    "2. **Linear regression və optimallaşdırma**:\n",
    "   Linear regression-da modelin parametrlərini optimallaşdırmaq üçün **gradient descent** kimi alqoritmlərdən istifadə edirik. Bu alqoritmlər **xəta funksiyasının törəməsini alır** (xəta funksiyası ümumiyyətlə **MSE** (Mean Squared Error) olur), lakin burada törəmə yalnız **parametrləri (θ₀, θ₁, θ₂, θ₃)** yeniləmək üçün istifadə olunur. Bu, **modelin parametrlərini optimallaşdırmaq** üçün edilir, **x²** və **x³**-ün öz törəmələri ilə bağlı deyil.\n",
    "\n",
    "3. **Modelin optimallaşdırılması**:\n",
    "   **Gradient descent** və ya başqa optimallaşdırma metodları **xəta funksiyasının törəməsini alır** ki, bu şəkildə modelin parametrlərini **yeniləyək**. **x²** və **x³** kimi polinom xüsusiyyətlər modelə daxil edilir, amma **onların törəməsi alınmaz**. Model yalnız **xüsusiyyətlər üzərində xətti əlaqə qurur**.\n",
    "\n",
    "### Nəticə:\n",
    "- **Linear regression** modelində **x²** və **x³** kimi xüsusiyyətlər **modelə daxil edilir**, amma **onların törəməsi alınmaz**.\n",
    "- **Törəmə yalnız xəta funksiyası üzərində alınır** ki, bu da **parametrlərin optimallaşdırılması** məqsədilə edilir. Polinom funksiyalar modelin dəyişənləri olur, amma model bu dəyişənlər üzərində **xətti əlaqə qurur**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728940a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8253300c",
   "metadata": {},
   "source": [
    "## SSE-nin və törəmənin izahı"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb463779",
   "metadata": {},
   "source": [
    "---\n",
    "Bəli, **Linear Regression** modelində **SSE** (Sum of Squared Errors) üçün törəmə alınır. Bu, **gradient descent** və ya başqa optimallaşdırma metodları vasitəsilə **modelin parametrlərini (θ₀, θ₁, θ₂, ...) yeniləmək** üçün istifadə olunur.\n",
    "\n",
    "### SSE-nin və törəmənin izahı:\n",
    "\n",
    "**SSE** (Sum of Squared Errors) modeli optimallaşdırarkən istifadə olunan **xəta funksiyası** (loss function)-dur və ümumiyyətlə aşağıdakı kimi ifadə edilir:\n",
    "\n",
    "$$\n",
    "SSE = \\sum_{i=1}^{m} \\left( y^{(i)} - \\hat{y}^{(i)} \\right)^2\n",
    "$$\n",
    "Burada:\n",
    "- $ y^{(i)} $: Həqiqi dəyər (real value).\n",
    "- $ \\hat{y}^{(i)} $: Proqnozlaşdırılmış dəyər (modelin verdiyi nəticə), yəni $ \\hat{y}^{(i)} = \\theta_0 + \\theta_1 x^{(i)} \\$.\n",
    "\n",
    "**SSE**, modelin səhvini ölçür və məqsədimiz **SSE-nin minimuma endirilməsi**dir. Bunun üçün **gradient descent** istifadə edilir.\n",
    "\n",
    "### SSE-nin törəməsi:\n",
    "\n",
    "**SSE**-nin törəməsini alaraq, **modelin parametrlərini (θ₀, θ₁, ...)** optimallaşdırırıq. İndi **θ₀** və **θ₁** üçün törəmələri tapaq.\n",
    "\n",
    "#### 1. **SSE-nin θ₀ üzrə törəməsi**:\n",
    "SSE-nin θ₀ üzrə törəməsi:\n",
    "$$\n",
    "\\frac{\\partial SSE}{\\partial \\theta_0} = \\frac{\\partial}{\\partial \\theta_0} \\sum_{i=1}^{m} \\left( y^{(i)} - (\\theta_0 + \\theta_1 x^{(i)}) \\right)^2\n",
    "$$\n",
    "Bu törəməni alaraq **θ₀**-ı optimallaşdırmağa çalışırıq.\n",
    "\n",
    "#### 2. **SSE-nin θ₁ üzrə törəməsi**:\n",
    "SSE-nin θ₁ üzrə törəməsi:\n",
    "$$\n",
    "\\frac{\\partial SSE}{\\partial \\theta_1} = \\frac{\\partial}{\\partial \\theta_1} \\sum_{i=1}^{m} \\left( y^{(i)} - (\\theta_0 + \\theta_1 x^{(i)}) \\right)^2\n",
    "$$\n",
    "Burada, **θ₁**-in də optimallaşdırılması üçün törəmə alınır.\n",
    "\n",
    "#### 3. **SSE-nin ümumi forması**:\n",
    "Ümumi SSE funksiyası:\n",
    "$$\n",
    "SSE = \\sum_{i=1}^{m} \\left( y^{(i)} - (\\theta_0 + \\theta_1 x^{(i)}) \\right)^2\n",
    "$$\n",
    "\n",
    "Bu funksiya **quadratic** olduğu üçün, törəmə alınması sadə olur və **θ₀** və **θ₁** üçün təhlil edilən nəticələr **sıfır** olmaqla parametrləri yeniləməyə imkan verir.\n",
    "\n",
    "### Gradient Descent və Törəmə:\n",
    "**Gradient descent** alqoritması SSE-nin törəmələrini istifadə edərək parametrləri optimallaşdırır. Bu, aşağıdakı kimi işləyir:\n",
    "\n",
    "1. **Başlanğıc qiymətləri**: Əvvəlcə parametrlərə (θ₀, θ₁) təsadüfi qiymətlər təyin edilir.\n",
    "2. **Törəmə alınır**: SSE funksiyasının törəmələri alınır (θ₀ və θ₁ üçün).\n",
    "3. **Yeniləmə qaydası**:\n",
    "$$\n",
    "\\theta_0 = \\theta_0 - \\alpha \\frac{\\partial SSE}{\\partial \\theta_0}\n",
    "$$\n",
    "$$\n",
    "\\theta_1 = \\theta_1 - \\alpha \\frac{\\partial SSE}{\\partial \\theta_1}\n",
    "$$\n",
    "Burada:\n",
    "- $ \\alpha $: **öyrənmə dərəcəsi** (learning rate).\n",
    "- Törəmə hər parametrlə bağlı yenilənir.\n",
    "\n",
    "4. **Yeniləmələr davam edir**: Törəmələr alınaraq parametrlər yenilənir, bu proses **SSE** minimuma enənə qədər davam edir.\n",
    "\n",
    "### Nəticə:\n",
    "- **SSE** xəta funksiyasının törəməsi alınır ki, bu da **modelin parametrlərini optimallaşdırmaq** məqsədilə istifadə olunur.\n",
    "- Bu törəmələr, **gradient descent** və ya başqa optimallaşdırma metodları ilə **θ₀**, **θ₁** və digər parametrləri tapmaq üçün tətbiq edilir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0402ee72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad06716f",
   "metadata": {},
   "source": [
    "## Linear Regression modelində  𝑦̂ (yəni proqnozlaşdırılmış dəyər) xətti tənlik"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551cef2b",
   "metadata": {},
   "source": [
    "Linear Regression modelində $ \\hat{y} $ (yəni proqnozlaşdırılmış dəyər) xətti tənlik vasitəsilə aşağıdakı şəkildə tapılır:\n",
    "\n",
    "$$\n",
    "\\hat{y} = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_n x_n\n",
    "$$\n",
    "\n",
    "Burada:\n",
    "\n",
    "- $ \\hat{y} $ — proqnozlaşdırılmış nəticə (dependent variable),\n",
    "- $ \\beta_0 $) — intercept (kəsilmə nöqtəsi, yəni $ x $-lərin 0 olduğu halda $ y $-in başlanğıc dəyəri),\n",
    "- $ \\beta_1, \\beta_2, \\dots, \\beta_n $ — müstəqil dəyişənlərin (features) əmsalları,\n",
    "- $ x_1, x_2, \\dots, x_n $ — müstəqil dəyişənlərin dəyərləri.\n",
    "\n",
    "### Məsələn:\n",
    "Bir dəyişənli Linear Regression üçün model aşağıdakı kimi yazılır:\n",
    "$$\n",
    "\\hat{y} = \\beta_0 + \\beta_1 x\n",
    "$$\n",
    "\n",
    "Əgər $ \\beta_0 = 2 $ və $ \\beta_1 = 3 $, $ x = 4 $ olduğu halda $ \\hat{y} $-i tapmaq üçün:\n",
    "$$\n",
    "\\hat{y} = 2 + 3 \\cdot 4 = 14\n",
    "$$\n",
    "\n",
    "Çox dəyişənli modeldə isə $ \\hat{y} $ hər bir $ x $-in uyğun əmsalı ilə çarpılaraq, nəticələr toplanır. Bu, Lineer Algebra ilə matris formasında daha sadə şəkildə hesablana bilər:\n",
    "\n",
    "$$\n",
    "\\hat{y} = X \\cdot \\beta\n",
    "$$\n",
    "\n",
    "Burada:\n",
    "-$ X $ — feature matrix,\n",
    "- $ \\beta $ — əmsallar vektoru."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7d6490",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d93aa2b",
   "metadata": {},
   "source": [
    "## $ SST $, $ SSE $, və $ SSR $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae80847",
   "metadata": {},
   "source": [
    "Linear Regression modelində $ SST $, $ SSE $, və $ SSR $ statistik dəyərlərdir və modelin effektivliyini ölçmək üçün istifadə olunur. Bunlar ümumilikdə dəyişkənlik (variance) analizi ilə əlaqədardır.\n",
    "\n",
    "### 1. **SST (Total Sum of Squares)**  \n",
    "Ümumi dəyişkənliyi ölçür. Yəni bütün $ y $ dəyərlərinin orta qiymətdən (mean) nə qədər uzaqda olduğunu göstərir.  \n",
    "Formula:  \n",
    "$$\n",
    "SST = \\sum_{i=1}^{n} (y_i - \\bar{y})^2\n",
    "$$ \n",
    "Burada:\n",
    "- $ y_i $ — faktiki dəyərlər (real data),\n",
    "- $\\bar{y} $ — faktiki dəyərlərin orta qiyməti.\n",
    "\n",
    "SST həm modellə izah edilən, həm də izah edilməyən dəyişkənliyi əhatə edir.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **SSR (Regression Sum of Squares)**  \n",
    "Modelin izah edə bildiyi dəyişkənliyi ölçür. Yəni proqnozlaşdırılmış dəyərlərin orta qiymətdən nə qədər uzaqda olduğunu göstərir.  \n",
    "Formula:  \n",
    "$$\n",
    "SSR = \\sum_{i=1}^{n} (\\hat{y}_i - \\bar{y})^2\n",
    "$$  \n",
    "Burada:\n",
    "- $ \\hat{y}_i $ — model tərəfindən proqnozlaşdırılmış dəyərlər,\n",
    "- $ \\bar{y} $ — faktiki dəyərlərin orta qiyməti.\n",
    "\n",
    "SSR nə qədər böyük olsa, modelin yaxşı işlədiyini göstərir.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **SSE (Error Sum of Squares)**  \n",
    "Modelin izah edə bilmədiyi dəyişkənliyi ölçür. Yəni faktiki dəyərlərlə proqnozlaşdırılmış dəyərlər arasındakı fərqi göstərir.  \n",
    "Formula:  \n",
    "$$\n",
    "SSE = \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\n",
    "$$  \n",
    "Burada:\n",
    "- $ y_i $ — faktiki dəyərlər,\n",
    "- $ \\hat{y}_i $ — modelin proqnozlaşdırdığı dəyərlər.\n",
    "\n",
    "SSE nə qədər kiçik olsa, modelin performansı bir o qədər yaxşıdır.\n",
    "\n",
    "---\n",
    "\n",
    "### SST, SSR və SSE arasındakı əlaqə\n",
    "Üç göstərici arasında aşağıdakı əlaqə mövcuddur:  \n",
    "$$\n",
    "SST = SSR + SSE\n",
    "$$ \n",
    "Bu, ümumi dəyişkənliyin ($ SST $) model tərəfindən izah edilən hissə ($ SSR $) və model tərəfindən izah edilə bilməyən hissəyə ($ SSE $) bölündüyünü göstərir.\n",
    "\n",
    "---\n",
    "\n",
    "### **Modelin Performansını Qiymətləndirmək**  \n",
    "R² (determinasiya əmsalı) bu göstəricilər əsasında hesablanır:\n",
    "$$ \n",
    "SSR = SST - SSE\n",
    "$$\n",
    "\n",
    "$$\n",
    "R^2 = \\frac{SSR}{SST} = 1 - \\frac{SSE}{SST}\n",
    "$$  \n",
    "- $ R^2 $ dəyəri 0 ilə 1 arasında olur.\n",
    "- 1-ə yaxın olduqda, model çox yaxşı izah edir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d855187c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34da9f3e",
   "metadata": {},
   "source": [
    "## SSR (Regression Sum of Squares) əhəmiyyəti"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e66ec4",
   "metadata": {},
   "source": [
    "### **SSR (Regression Sum of Squares) əhəmiyyəti**  \n",
    "\n",
    "SSR, lineer regression modelində **modelin izah edə bildiyi dəyişkənliyi** ölçür. Bu göstərici, modelin verilənlərdəki ümumi variasiyanın (dəyişkənliyin) hansı hissəsini izah etdiyini göstərir. SSR dəyərinin əhəmiyyətini bir neçə aspektdən izah etmək olar:\n",
    "\n",
    "---\n",
    "\n",
    "### 1. **Modelin Gücünü Göstərir**  \n",
    "SSR dəyəri nə qədər böyükdürsə, model faktiki nəticələri o qədər yaxşı izah edir.  \n",
    "- **Böyük SSR**: Model faktiki dəyərlərin orta qiymətinə (mean-ə) nisbətən proqnozları daha yaxşı izah edir.  \n",
    "- **Kiçik SSR**: Model çox az dəyişkənliyi izah edir, bu da modelin zəif olduğunu göstərə bilər.  \n",
    "\n",
    "---\n",
    "\n",
    "### 2. **R² (Determinasiya Əmsalı) ilə Bağlantısı**  \n",
    "SSR, $ R^2$ əmsalının hesablanmasında əsas rol oynayır:  \n",
    "$$\n",
    "R^2 = \\frac{SSR}{SST}\n",
    "$$ \n",
    "Burada:\n",
    "- SSR – modelin izah etdiyi dəyişkənlik,\n",
    "- SST – ümumi dəyişkənlik.  \n",
    "\n",
    "**Əgər SSR yüksəkdirsə, $R^2 $ dəyəri də yüksək olacaq**. Bu, modelin ümumi dəyişkənliyin böyük hissəsini izah etdiyini və yaxşı performans göstərdiyini ifadə edir.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **Model Seçimində İstifadə Edilir**  \n",
    "SSR, müxtəlif modelləri müqayisə etmək üçün istifadə edilə bilər.  \n",
    "- İki modeldən hansının SSR dəyəri daha böyükdürsə, həmin model məlumatların strukturunu daha yaxşı izah edir.  \n",
    "\n",
    "Məsələn, sadə lineer regression modeli ilə çox dəyişkənli regression modeli müqayisə edilərkən SSR dəyərləri təhlil edilə bilər.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. **Modelin Öyrənmə Qabiliyyətini Təmsil Edir**  \n",
    "SSR dəyəri modelin **faktiki dəyərlərlə orta qiymət arasındakı fərqi nə qədər yaxşı modelləşdirə bildiyini** göstərir. Bu, verilənlərdəki əsas tendensiyaların düzgün tutulub-tutulmadığını müəyyənləşdirir.\n",
    "\n",
    "---\n",
    "\n",
    "### Nəticə  \n",
    "SSR, lineer regression modelində verilənlərin izah edilə bilən variasiyasını ölçdüyü üçün modelin gücünü və uyğunluğunu təhlil etməkdə kritik rol oynayır. SSR yüksəkdirsə və SSE kiçikdirsə, bu, modelin yaxşı performans göstərdiyini və faktiki nəticələrə yaxın proqnozlar verdiyini göstərir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf870238",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1945136",
   "metadata": {},
   "source": [
    "## Xəta Funksiyasının Minimallaşdırılması"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c33122",
   "metadata": {},
   "source": [
    "Linear Regression modelində xəta funksiyası, yəni **Mean Squared Error (MSE)**, proqnozlaşdırılmış dəyərlər ($ \\hat{y} $) ilə faktiki dəyərlər ($ y $) arasındakı fərqlərin kvadrat ortalaması kimi müəyyən edilir. Bu funksiyanın **törəməsi sıfıra bərabər edilərək**, xəta minimal səviyyəyə endirilir və ən uyğun $ \\beta $ əmsalları tapılır.\n",
    "\n",
    "---\n",
    "\n",
    "### **Xəta Funksiyası (MSE)**  \n",
    "Xəta funksiyası belə təyin olunur:\n",
    "$$\n",
    "L(\\beta) = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\n",
    "$$\n",
    "Burada:\n",
    "- $ y_i $ — faktiki dəyərlər,\n",
    "- $ \\hat{y}_i $ — proqnozlaşdırılmış dəyərlər ($ \\hat{y}_i = \\beta_0 + \\beta_1 x_i $).\n",
    "\n",
    "Xəta funksiyasını minimallaşdırmaq üçün parametrlərin ($\\beta_0 $ və $ \\beta_1 $) törəmələri sıfıra bərabərlənir.\n",
    "\n",
    "---\n",
    "\n",
    "### **Proqnozlaşdırılmış Dəyərlərin ( \\$ \\hat{y} \\$) İfadəsi**  \n",
    "Proqnozlaşdırılmış dəyər xətti modelə əsasən belə yazılır:\n",
    "$$\n",
    "\\hat{y}_i = \\beta_0 + \\beta_1 x_i\n",
    "$$\n",
    "Bu, faktiki olaraq modelin xəttini təyin edir.\n",
    "\n",
    "---\n",
    "\n",
    "### **Xəta Funksiyasının Minimallaşdırılması**  \n",
    "\n",
    "**MSE** funksiyasının **optimallaşdırılması** üçün $\\beta_0$ və $\\beta_1$-ə görə **qismən törəmələri sıfıra bərabər** edib həll edək. Bu, xətti regresiya üçün parametrlərin analitik həllini tapmağa imkan verəcək.  \n",
    "\n",
    "---\n",
    "\n",
    "### 1. **MSE funksiyası**:\n",
    "$$\n",
    "L(\\beta_0, \\beta_1) = \\frac{1}{n} \\sum_{i=1}^n \\big(y_i - (\\beta_0 + \\beta_1 x_i)\\big)^2\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **$\\beta_0$-a görə qismən törəmə**:\n",
    "Törəmə:\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial \\beta_0} = -\\frac{2}{n} \\sum_{i=1}^n (y_i - \\beta_0 - \\beta_1 x_i)\n",
    "$$\n",
    "\n",
    "Bunu sıfıra bərabər edirik:\n",
    "$$\n",
    "-\\frac{2}{n} \\sum_{i=1}^n (y_i - \\beta_0 - \\beta_1 x_i) = 0\n",
    "$$\n",
    "Sadələşdirək:\n",
    "$$\n",
    "\\sum_{i=1}^n (y_i - \\beta_0 - \\beta_1 x_i) = 0\n",
    "$$\n",
    "$$\n",
    "\\sum_{i=1}^n y_i - n\\beta_0 - \\beta_1 \\sum_{i=1}^n x_i = 0\n",
    "$$\n",
    "$$\n",
    "n\\beta_0 = \\sum_{i=1}^n y_i - \\beta_1 \\sum_{i=1}^n x_i\n",
    "$$\n",
    "$$\n",
    "\\beta_0 = \\frac{\\sum_{i=1}^n y_i}{n} - \\beta_1 \\frac{\\sum_{i=1}^n x_i}{n}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **$\\beta_1$-ə görə qismən törəmə**:\n",
    "Törəmə:\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial \\beta_1} = -\\frac{2}{n} \\sum_{i=1}^n x_i (y_i - \\beta_0 - \\beta_1 x_i)\n",
    "$$\n",
    "\n",
    "Bunu sıfıra bərabər edirik:\n",
    "$$\n",
    "-\\frac{2}{n} \\sum_{i=1}^n x_i (y_i - \\beta_0 - \\beta_1 x_i) = 0\n",
    "$$\n",
    "Sadələşdirək:\n",
    "$$\n",
    "\\sum_{i=1}^n x_i (y_i - \\beta_0 - \\beta_1 x_i) = 0\n",
    "$$\n",
    "$$\n",
    "\\sum_{i=1}^n x_i y_i - \\beta_0 \\sum_{i=1}^n x_i - \\beta_1 \\sum_{i=1}^n x_i^2 = 0\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### 4. **$\\beta_0$ ifadəsini əvəz edək**:\n",
    "Əvəzləmə üçün:\n",
    "$$\n",
    "\\beta_0 = \\frac{\\sum_{i=1}^n y_i}{n} - \\beta_1 \\frac{\\sum_{i=1}^n x_i}{n}\n",
    "$$\n",
    "\n",
    "Yuxarıdakı ifadəni $\\beta_0$ yerinə qoyduqdan sonra $\\beta_1$-i sadələşdirməklə belə nəticə əldə edirik:\n",
    "\n",
    "$$\n",
    "\\beta_1 = \\frac{\\sum_{i=1}^n (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^n (x_i - \\bar{x})^2}\n",
    "$$\n",
    "\n",
    "Burada:\n",
    "- $\\bar{x} = \\frac{\\sum_{i=1}^n x_i}{n}$ — $x$ dəyişəninin orta qiyməti,\n",
    "- $\\bar{y} = \\frac{\\sum_{i=1}^n y_i}{n}$ — $y$ dəyişəninin orta qiyməti.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. **$\\beta_0$ və $\\beta_1$-in final nəticələri**:\n",
    "1. $\\beta_1$:\n",
    "$$\n",
    "\\beta_1 = \\frac{\\sum_{i=1}^n (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^n (x_i - \\bar{x})^2}\n",
    "$$\n",
    "\n",
    "2. $\\beta_0$:\n",
    "$$\n",
    "\\beta_0 = \\bar{y} - \\beta_1 \\bar{x}\n",
    "$$\n",
    "\n",
    "Bu nəticələr xətti regresiya üçün parametrləri hesablamaq üçün istifadə olunur.\n",
    "\n",
    "---\n",
    "\n",
    "### **Faktiki Dəyərin ($ y $) İfadəsi**\n",
    "Faktiki dəyərlər model tərəfindən verilmir. Onlar datada olan müşahidə edilmiş dəyərlərdir ($ y_i $).  \n",
    "\n",
    "Proqnozlaşdırılmış dəyərlərlə faktiki dəyərlər arasında fərqi ($ y_i - \\hat{y}_i $) minimallaşdıraraq, proqnozun faktiki müşahidələrə nə qədər yaxın olduğunu təmin edirik.\n",
    "\n",
    "---\n",
    "\n",
    "### **Əsas Məntiq**\n",
    "- **$ \\hat{y}_i $**: Proqnozlaşdırılmış dəyərdir ($ \\hat{y}_i = \\beta_0 + \\beta_1 x_i $).\n",
    "- **$ y_i $**: Faktiki müşahidə olunan dəyərdir.\n",
    "- $ (y_i - \\hat{y}_i)^2 $ fərqlərin kvadratı xəta funksiyasını təyin edir.\n",
    "- Xəta funksiyasının törəməsi sıfıra bərabər edilməklə optimal \\( \\beta \\)-lar hesablanır.\n",
    "\n",
    "Beləliklə, xəta minimallaşdırıldıqda ən uyğun xətt tapılır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e7676b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "92eb1b0a",
   "metadata": {},
   "source": [
    "## Müxtəlif dəyişənli Xətti Reqressiya üçün Parametlərin düsturu "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59dee3f",
   "metadata": {},
   "source": [
    "\n",
    "### **1. Tək dəyişənli xətti reqressiya üçün: ($y = b_0 + b_1x_1$) parametrlərin son ifadələri belədir:**\n",
    "$$\n",
    "b_1 = \\frac{\\sum (x - \\bar{x})(y - \\bar{y})}{\\sum (x - \\bar{x})^2}\n",
    "$$\n",
    "\n",
    "$$\n",
    "b_0 = \\bar{y} - b_1 \\bar{x}.\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "### **2. İki dəyişənli xətti reqressiya modeli:  ($y = b_0 + b_1x_1 + b_2x_2$) parametrlərin son ifadələri belədir:** \n",
    "\n",
    "\n",
    "$$\n",
    "b_1 = \\frac{\\sum (x_1 - \\bar{x_1})(y - \\bar{y}) - b_2 \\sum (x_1 - \\bar{x_1})(x_2 - \\bar{x_2})}{\\sum (x_1 - \\bar{x_1})^2},\n",
    "$$\n",
    "\n",
    "$$\n",
    "b_2 = \\frac{\\sum (x_2 - \\bar{x_2})(y - \\bar{y}) - b_1 \\sum (x_1 - \\bar{x_1})(x_2 - \\bar{x_2})}{\\sum (x_2 - \\bar{x_2})^2}.\n",
    "$$\n",
    "\n",
    "$$\n",
    "b_0 = \\bar{y} - b_1 \\bar{x_1} - b_2 \\bar{x_2}.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Üç dəyişənli xətti reqressiya modeli üçün (yəni $ y = b_0 + b_1x_1 + b_2x_2 + b_3x_3 $) parametrlərin son ifadələri belədir:**\n",
    "\n",
    "$$ b_1 = \\frac{\\sum (x_1 - \\bar{x}_1)(y - \\bar{y}) - b_2 \\sum (x_1 - \\bar{x}_1)(x_2 - \\bar{x}_2) - b_3 \\sum (x_1 - \\bar{x}_1)(x_3 - \\bar{x}_3)}{\\sum (x_1 - \\bar{x}_1)^2}\n",
    "$$\n",
    "\n",
    "$$ b_2 = \\frac{\\sum (x_2 - \\bar{x}_2)(y - \\bar{y}) - b_1 \\sum (x_1 - \\bar{x}_1)(x_2 - \\bar{x}_2) - b_3 \\sum (x_2 - \\bar{x}_2)(x_3 - \\bar{x}_3)}{\\sum (x_2 - \\bar{x}_2)^2}\n",
    "$$\n",
    "\n",
    "$$ b_3 = \\frac{\\sum (x_3 - \\bar{x}_3)(y - \\bar{y}) - b_1 \\sum (x_1 - \\bar{x}_1)(x_3 - \\bar{x}_3) - b_2 \\sum (x_2 - \\bar{x}_2)(x_3 - \\bar{x}_3)}{\\sum (x_3 - \\bar{x}_3)^2} \n",
    "$$\n",
    "\n",
    "$$ b_0 = \\bar{y} - b_1 \\bar{x}_1 - b_2 \\bar{x}_2 - b_3 \\bar{x}_3 \n",
    "$$ \n",
    "\n",
    "Bunlar ən kiçik kvadratlar üsulu ilə tapılmış **son nəticələrdir**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79739119",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cac9ac1f",
   "metadata": {},
   "source": [
    "## $x^2$ funksiyasının artma və azalma aralıqlar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445e6132",
   "metadata": {},
   "source": [
    "$x^2$ funksiyasının artma və azalma aralıqları, funksiyanın törəməsinə əsaslanaraq müəyyən edilir.\n",
    "\n",
    "1. **Funksiyanın törəməsi**:\n",
    "   \n",
    "   $f(x) = x^2$ funksiyasının törəməsi:\n",
    "   $$\n",
    "   f'(x) = 2x\n",
    "   $$\n",
    "\n",
    "2. **Artma və Azalma**:\n",
    "   - Funksiya **artır** (yəni $f'(x) > 0$) olduğunda, funksiyanın dəyəri nöqtədən nöqtəyə artacaq.\n",
    "   - Funksiya **azalır** (yəni $f'(x) < 0$) olduğunda, funksiyanın dəyəri nöqtədən nöqtəyə azalacaq.\n",
    "\n",
    "3. **Törəmənin işarəsi**:\n",
    "   - **$f'(x) = 2x$ olduğu üçün**:\n",
    "     - Funksiya **azalır** $x < 0$ (negativ $x$-də), çünki $f'(x) < 0$.\n",
    "     - Funksiya **artar** $x > 0$ (müsbət $x$-də), çünki $f'(x) > 0$.\n",
    "     - Funksiya $x = 0$-da sabitdir, çünki burada $f'(x) = 0$.\n",
    "\n",
    "4. **Artma və Azalma Aralıqları**:\n",
    "   - **Artma aralığı**: $ (0, +\\infty) $\n",
    "   - **Azalma aralığı**: $ (-\\infty, 0) $\n",
    "\n",
    "Yəni, $x^2$ funksiyası:\n",
    "- $x = 0$-dan əvvəl azalan (negativ $x$-də),\n",
    "- $x = 0$-dan sonra artan (müsbət $x$-də) bir funksiyadır."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7695b4ee",
   "metadata": {},
   "source": [
    "## $ f(x) = x^2 $ funksiyasının **minimum** və **maksimum** nöqtələri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8a11db",
   "metadata": {},
   "source": [
    "$ f(x) = x^2 $ funksiyasının **minimum** və **maksimum** nöqtələrini tapmaq üçün əvvəlcə funksiyanın təhlilini edək:\n",
    "\n",
    "1. **Funksiyanın törəməsi**:\n",
    "   $$\n",
    "   f'(x) = 2x\n",
    "   $$\n",
    "   Törəmənin sıfır olduğu nöqtə, funksiya üçün mümkün bir ekstremum nöqtəsi ola bilər. Törəməni sıfıra bərabərləyirik:\n",
    "   $$\n",
    "   2x = 0 \\quad \\Rightarrow \\quad x = 0\n",
    "   $$\n",
    "   Bu nöqtə $x = 0$ funksiyasının ekstremum nöqtəsi ola bilər.\n",
    "\n",
    "2. **Minimum və Maksimum**:\n",
    "   - **Minimum nöqtəsi**: Funksiya $x = 0$-da ən aşağı dəyəri alır. Çünki $x^2$ funksiyası, $x$ artdıqca və ya azaldıqca müsbət dəyər alır. Bu, funksiyanın bir **minimum** nöqtəsidir.\n",
    "     - **Minimum**: $ f(0) = 0^2 = 0 $\n",
    "   \n",
    "   - **Maksimum nöqtəsi**: $f(x) = x^2$ funksiyası təkcə aşağıya doğru azaldıqdan sonra yenidən artmağa başlayır. Yəni, funksiyanın maksimum nöqtəsi yoxdur, çünki $x \\to \\infty$ və ya $ \\to -\\infty$ olduqda funksiya daha böyük müsbət qiymətlər alır.\n",
    "\n",
    "**Nəticə**:\n",
    "- **Minimum** nöqtəsi $x = 0$ və $f(0) = 0$-dır.\n",
    "- Funksiyanın **maksimum** nöqtəsi yoxdur (sonsuz dəyərə qədər böyüyə bilər)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6aefbca",
   "metadata": {},
   "source": [
    "## İkinci törəmə ilə minimum və maksimum nöqtələrini yoxlamaq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e5f8f0",
   "metadata": {},
   "source": [
    "İkinci törəmə ilə minimum və maksimum nöqtələrini yoxlamaq üçün funksiyanın ikinci törəməsini tapmalıyıq.\n",
    "\n",
    "Funksiya: \n",
    "$$\n",
    "f(x) = x^2\n",
    "$$\n",
    "\n",
    "1. **Birinci törəmə**: \n",
    "$$\n",
    "f'(x) = 2x\n",
    "$$\n",
    "\n",
    "2. **İkinci törəmə**:\n",
    "$$\n",
    "f''(x) = 2\n",
    "$$\n",
    "\n",
    "İkinci törəmənin işarəsi funksiyanın necə davranacağına (yəni, minimum və maksimum nöqtələrini) müəyyən edir.\n",
    "\n",
    "- Əgər $ f''(x) > 0 $ isə, funksiyada **minimum** nöqtəsi var.\n",
    "- Əgər $ f''(x) < 0 $ isə, funksiyada **maksimum** nöqtəsi var.\n",
    "- Əgər $ f''(x) = 0 $ isə, bu nöqtə haqqında daha çox təhlil tələb olunur.\n",
    "\n",
    "Bu halda:\n",
    "$$\n",
    "f''(x) = 2 > 0\n",
    "$$\n",
    "\n",
    "Deməli, $ f(x) = x^2 $ funksiyasının hər yerdə **minimum** nöqtəsi olduğunu göstərir. Bu, funksiyanın açılan parabola (yuxarıya doğru açılan) olması ilə əlaqədardır. Həmçinin, minimum nöqtəsi $ x = 0 $-da yerləşir, yəni:\n",
    "$$\n",
    "f(0) = 0^2 = 0\n",
    "$$\n",
    "\n",
    "**Nəticə**:\n",
    "- **Minimum nöqtəsi**: $ x = 0 $ və $ f(0) = 0 $.\n",
    "- **Maksimum nöqtəsi yoxdur** (çünki $ f''(x) > 0 $ funksiyanın hər yerdə minimum olduğunu göstərir)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd99dafb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "48eb7baf",
   "metadata": {},
   "source": [
    "## **Scikit-learn**-dəki `LinearRegression` modeli ümumiyyətlə **`Toxunanın` tənliyindən istifadə etmir**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57dc6f92",
   "metadata": {},
   "source": [
    "Bəli, tamamilə doğrudur. **Scikit-learn**-dəki `LinearRegression` modeli ümumiyyətlə **toxunanın tənliyindən istifadə etmir**. Bunun əvəzinə, o, **ən kiçik kvadratlar metodundan** istifadə edir. Yəni, bu model verilən bütün məlumat nöqtələrinə qlobal şəkildə uyğun gələn bir xətt tapmağa çalışır, və bu xəttin riyazi təsviri **statistik ən yaxşı uyğunluq** prinsipi ilə qurulur. \n",
    "\n",
    "Toxunanın tənliyi isə lokal olaraq bir nöqtədə bir əyriyə (funksiyaya) uyğun xətti təmsil edir. Scikit-learn LinearRegression modeli bir funksiyanın müəyyən bir nöqtədəki törəməsindən və ya toxunanın tənliyindən asılı deyil.\n",
    "\n",
    "---\n",
    "\n",
    "### **Əsas Fərqlər:**\n",
    "\n",
    "| **Toxunanın Tənliyi**                                        | **Linear Regression (Scikit-learn)**                     |\n",
    "|--------------------------------------------------------------|----------------------------------------------------------|\n",
    "| Lokal olaraq bir nöqtədəki xətti yaxınlaşmanı təsvir edir.   | Qlobal olaraq bütün verilənlərə uyğun xətti model qurur. |\n",
    "| Törəməyə əsaslanır ($ f'(x) $).                           | Ən kiçik kvadratlar metodundan istifadə edir.            |\n",
    "| Sadəcə bir nöqtədə istifadə olunur (\\$ x_0 $-da).           | Bütün verilənlər dəstinə uyğun gəlir.                   |\n",
    "\n",
    "---\n",
    "\n",
    "### **Nəticə:**\n",
    "- **Scikit-learn**-dəki `LinearRegression` modeli **toxunanın tənliyindən istifadə etmir**.\n",
    "- O, bütün verilənlər üçün qlobal bir xətt qurmaq üçün statistik üsullardan (ən kiçik kvadratlar metodu) istifadə edir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cafa9f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a74fd301",
   "metadata": {},
   "source": [
    "## **Ən Kiçik Kvadratlar Metodu**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d55721e",
   "metadata": {},
   "source": [
    "**Ən Kiçik Kvadratlar Metodu** ($ \\text{Ordinary Least Squares} $, OLS) xətti regresiyanın əsas prinsipidir. Bu metodun məqsədi verilən məlumat dəstinə ən yaxşı uyğun gələn xətti tapmaqdır. \"Ən yaxşı xətt\" isə faktiki (real) dəyərlərlə proqnozlaşdırılmış dəyərlər arasındakı fərqlərin kvadratlarının cəmini minimuma endirən xəttdir.\n",
    "\n",
    "---\n",
    "\n",
    "### **Əsas Fikir:**\n",
    "Məlumat dəstində hər bir məlumat nöqtəsi üçün faktiki dəyər ($ y_i $) ilə modelin proqnozlaşdırdığı dəyər ($ \\hat{y}_i $) arasında fərq (qalıq və ya səhv) olur. Bu fərqlərin kvadratlarının cəmi minimum olan xətti tapmaq üçün OLS metodundan istifadə edilir.\n",
    "\n",
    "#### **Formul:**\n",
    "OLS metodunun məqsədi aşağıdakı itki funksiyasını minimallaşdırmaqdır:\n",
    "$$\n",
    "\\text{Loss Function} = \\sum_{i=1}^n (y_i - \\hat{y}_i)^2\n",
    "$$\n",
    "Burada:\n",
    "- $ y_i $: Faktiki (real) dəyərlər,\n",
    "- $ \\hat{y}_i $: Proqnozlaşdırılmış dəyərlər ($ \\hat{y}_i = \\beta_0 + \\beta_1 x_i $),\n",
    "- $ n $: Məlumat dəstindəki nöqtələrin sayı.\n",
    "\n",
    "---\n",
    "\n",
    "### **Metodun Addımları:**\n",
    "\n",
    "1. **Xətti Model Tənliyi:**\n",
    "   Ən sadə xətti regresiya modeli belə görünür:\n",
    "   $$\n",
    "   y = \\beta_0 + \\beta_1 x + \\epsilon\n",
    "   $$\n",
    "   Burada:\n",
    "   - $ \\beta_0 $: Intercept (y oxunu kəsdiyi nöqtə),\n",
    "   - $ \\beta_1 $: Meyil (slope),\n",
    "   - $ \\epsilon $: Qalıq (səhv).\n",
    "\n",
    "2. **Hədəf:**\n",
    "   $\\beta_0 $ və $\\beta_1 $ parametrlərini elə seçmək lazımdır ki, faktiki və proqnozlaşdırılmış dəyərlər arasındakı fərqlərin kvadratlarının cəmi minimum olsun:\n",
    "   $$\n",
    "   \\min_{\\beta_0, \\beta_1} \\sum_{i=1}^n \\left( y_i - (\\beta_0 + \\beta_1 x_i) \\right)^2\n",
    "   $$\n",
    "\n",
    "3. **Hesablamalar:**\n",
    "   $ \\beta_0 $ və $ \\beta_1 $-nin analitik həlləri **törəmə** vasitəsilə hesablanır:\n",
    "   $$\n",
    "   \\beta_1 = \\frac{\\sum_{i=1}^n (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^n (x_i - \\bar{x})^2}\n",
    "   $$\n",
    "   $$\n",
    "   \\beta_0 = \\bar{y} - \\beta_1 \\bar{x}\n",
    "   $$\n",
    "   Burada:\n",
    "   - $ \\bar{x} $: $ x $-lərin orta qiyməti,\n",
    "   - $\\bar{y} $: $ y $-lərin orta qiyməti.\n",
    "\n",
    "4. **Proqnozlaşdırma:**\n",
    "   Tapılan $ \\beta_0 $ və $ \\beta_1 $ ilə model belə yazılır:\n",
    "   $$\n",
    "   \\hat{y} = \\beta_0 + \\beta_1 x\n",
    "   $$\n",
    "\n",
    "---\n",
    "\n",
    "### **Metodun İdeyası Qrafikdə:**\n",
    "\n",
    "1. **Verilmiş məlumat nöqtələri:** Bunlar (x, y) koordinatlarında qrafikdə işarələnir.\n",
    "2. **Xətti uyğunlaşma xətti:** Bu xətt $ \\hat{y} = \\beta_0 + \\beta_1 x $ tənliyinə uyğun gəlir.\n",
    "3. **Qalıqlar ($y_i - \\hat{y}_i $:** Faktiki dəyərlə proqnozlaşdırılmış dəyər arasındakı şaquli məsafədir.\n",
    "   - Bu qalıqların kvadratlarının cəmi minimum olan xətt seçilir.\n",
    "\n",
    "---\n",
    "\n",
    "### **Praktiki Məsələn:**\n",
    "\n",
    "Tutaq ki, bir insanın çəkisi ($ y $) ilə boyu ($ x $) arasında xətti bir əlaqə qurmaq istəyirsiniz. Məlumat belədir:\n",
    "\n",
    "| Boy (x) (m) | Çəki (y) (kg) |\n",
    "|-------------|---------------|\n",
    "| 1.5         | 50            |\n",
    "| 1.6         | 55            |\n",
    "| 1.7         | 65            |\n",
    "| 1.8         | 70            |\n",
    "\n",
    "Ən kiçik kvadratlar metodu istifadə edərək $ \\beta_0 $ və $\\beta_1 $-ni hesablamaqla, çəki ilə boy arasındakı ən uyğun xətti tapacaqsınız.\n",
    "\n",
    "---\n",
    "\n",
    "### **Əsas Üstünlükləri:**\n",
    "\n",
    "1. **Sadəlik:** Asan başa düşülür və tətbiq edilir.\n",
    "2. **Analitik həll:** OLS metodu parametr təxminləri üçün dəqiq analitik ifadələr verir.\n",
    "3. **Optimal uyğunlaşma:** Verilən məlumatlara ən yaxşı uyğun gələn xətti təmin edir.\n",
    "\n",
    "---\n",
    "\n",
    "Əgər qrafiklə izah etmək və ya nümunə kod vermək istəyirsinizsə, əlavə soruşa bilərsiniz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62772d58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
